{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46f6a1f0-50c7-4da0-b6e9-aa067ab68c65",
   "metadata": {},
   "source": [
    "# AI Powered Resume Ranker and Analyzer\n",
    "#### Final Project for AICTE internship on AI: TechSaksham, A Joint CSR initiative of MICROSOFT & SAP.\n",
    "### By Sanju S\n",
    "\n",
    "Linkedin: [@Sanju26](https://www.linkedin.com/in/sanju26/)\n",
    "\n",
    "Github: [@Sanju26Honey](https://github.com/sanju26honey)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e964ff24-585b-469e-a244-7f959d648827",
   "metadata": {},
   "source": [
    "#### Import and download required Packages and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e1e1bc-aed0-4256-ad2e-9b6ddc7ce500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from PyPDF2 import PdfReader\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import pytesseract\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2ea307-a9c4-4f57-bc55-712105d40d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4546934b-7b2f-48ee-9364-6d60cefc62d6",
   "metadata": {},
   "source": [
    "#### Extract text from PDF Files.\n",
    "PDFPlumber was used over PDFReader due to incorrect parsing of spaces by PDFReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38974e53-01b1-467f-96c7-332f352e7212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "\n",
    "def extract_text_from_pdf(file):\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(file) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26befa7-d9aa-4a6b-b586-c440edd66507",
   "metadata": {},
   "source": [
    "#### Process Text\n",
    "The most important part of the project. This is where all the unnecessary stopwords are removed, regex is applied, and lemmatized for further Natural Language Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2b9b9b-bc1b-45a0-b3d5-b8a45b03127d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(text):\n",
    "    review=re.sub(pattern=r'[^a-zA-Z]', repl=' ', string=text)\n",
    "    review=review.lower()\n",
    "    \n",
    "    review_word=review.split(' ')\n",
    "    review_word=[word for word in review_word if word not in set(stopwords.words('english'))]\n",
    "    review_word=[word for word in review_word if len(word) > 3]\n",
    "    # Remove words which tend to appear in the resume but not in the job description, leading to inaccuracies in ranking\n",
    "    review_word=[word for word in review_word if word not in [\"linkedin\",\"github\",\"objective\",\"summary\",\"references\"]]\n",
    "    # Remove words which tend to appear in the job description but not in the resume, leading to inaccuracies in ranking\n",
    "    review_word=[word for word in review_word if word not in [\"job\",\"canditate\",\"requirements\",\"responsibilities\",\"description\",\"location\",\"date\",\"title\"]]\n",
    "    # Remove months of the year, which usually do not add context\n",
    "    review_word=[word for word in review_word if word not in [\"jan\",\"january\",\"feb\",\"february\",\"mar\",\"march\",\"apr\",\"april\",\"may\",\"jun\",\"june\",\"jul\",\"july\",\"aug\",\"august\",\"sept\",\"september\",\"sep\",\"oct\",\"october\",\"nov\",\"november\",\"dec\",\"december\"]]\n",
    "    review_word=[word.strip() for word in review_word]\n",
    "    # review_word=[remove_entities(word) for word in review_word]\n",
    "    # return review\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    review=[lemmatizer.lemmatize(word, wordnet.VERB) for word in review_word]\n",
    "    \n",
    "    review=' '.join(word.strip() for word in review)\n",
    "    return review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed6d884-49a0-46b4-bc25-7a3fd5f3c3ed",
   "metadata": {},
   "source": [
    "#### Ranking Resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9ec4f3-127b-4495-b8c5-e9fac06cc7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to rank resumes based on job description\n",
    "def rank_resumes(job_description, resumes):\n",
    "    # Combine job description with resumes\n",
    "    documents = [job_description] + resumes\n",
    "    vectorizer = TfidfVectorizer().fit_transform(documents)\n",
    "    vectors = vectorizer.toarray()\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    job_description_vector = vectors[0]\n",
    "    resume_vectors = vectors[1:]\n",
    "    cosine_similarities = cosine_similarity([job_description_vector], resume_vectors).flatten()\n",
    "    \n",
    "    return cosine_similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7cec90-ba13-48b0-bdcd-945921227b59",
   "metadata": {},
   "source": [
    "### UI\n",
    "HTML is used to build the User Interface due to its simplicity. Bootstrap CDN is used for extensive styling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048ed889-d2e1-4808-80f9-31e0b05984d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "st.set_page_config(layout=\"wide\")\n",
    "\n",
    "\n",
    "html='''\n",
    "<link href=\"https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css\" rel=\"stylesheet\" integrity=\"sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC\" crossorigin=\"anonymous\">\n",
    "<script src=\"https://code.jquery.com/jquery-3.2.1.slim.min.js\" integrity=\"sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN\" crossorigin=\"anonymous\"></script>\n",
    "<script src=\"https://maxcdn.bootstrapcdn.com/bootstrap/5.0.0/js/bootstrap.min.js\" integrity=\"sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl\" crossorigin=\"anonymous\"></script>\n",
    "<style>\n",
    "    html,body,#stMarkdownContainer {\n",
    "        height: 100% !important;\n",
    "        width: 100% !important\n",
    "    }\n",
    "    .stMainBlockContainer  {\n",
    "        padding:0;\n",
    "        margin:0;\n",
    "    }\n",
    "    .page {\n",
    "        height: 100vh !important;\n",
    "    }\n",
    "    .st-key-container {\n",
    "        padding:10%;\n",
    "        overflow:hidden;\n",
    "        width:100% !important;\n",
    "    }\n",
    "    .stMarkdown, .stElementContainer {\n",
    "        max-width:100% !important;\n",
    "    }\n",
    "    .stFileUploader, .st-key-element2 {\n",
    "        max-width: 75% !important;\n",
    "    }\n",
    "    .stTextArea {\n",
    "        max-width:100%;\n",
    "    }\n",
    "</style>    \n",
    "<div class=\"px-4 py-5 w-100 text-left d-flex align-items-center page\">\n",
    "    <div>\n",
    "        <div class=\"col-lg-9 mx-auto\">\n",
    "            <h1 class=\"display-3 fw-bold\">Resume Ranker and Analyzer</h1>\n",
    "            <p class=\"lead mb-4\">The ultimate tool to revolutionize hiring workflows. This Resume Analyzer streamlines the recruitment process by leveraging cutting-edge technology to rank resumes, visualize key insights, and identify skill gaps‚Äîall in just a few clicks. Experience the future of talent acquisition, designed to make your decisions smarter and faster.</p>\n",
    "            <div class=\"\">\n",
    "            <span class=\"lead\">Developed with ‚ù§Ô∏è by <a href=\"https://sanju26honey.github.io\" class=\"text-decoration-none\">Sanju</a><br/><br/>\n",
    "            <a href=\"#step-1-upload-resumes\" class=\"btn me-3 p-3 px-5 text-decoration-none text-white\" style=\"background: #019161\">Get Started</a><a href=\"#Page2\" class=\"btn me-3 p-3 px-5 btn-dark text-decoration-none text-white\">Know More</a>\n",
    "            </div>\n",
    "            <!-- <p class=\"text-muted\">Scroll to know more</p> -->\n",
    "        </div>\n",
    "    </div>\n",
    "</div>\n",
    "<div class=\"px-4 py-5 my-5 text-left d-flex align-items-center page\" id=\"Page2\">\n",
    "    <div>\n",
    "        <div class=\"col-lg-10 mx-auto\">\n",
    "            <h1 class=\"\">Features</h1>\n",
    "            <br>\n",
    "            <div class=\"row\">\n",
    "                <div class=\"feature col text-justify\">\n",
    "                    <div>\n",
    "                        <h2>ü•á Rank Resumes</h2>\n",
    "                        <p>Leverage advanced NLP algorithms to rank resumes based on their alignment with job descriptions, ensuring the most suitable candidates are prioritized.</p>\n",
    "                    </div>\n",
    "                </div>\n",
    "                <div class=\"feature col text-justify\">\n",
    "                    <div>\n",
    "                        <h2>üîé Keyword Analysis</h2>\n",
    "                        <p>Identify and highlight critical keywords to evaluate resume relevance, detect missing skills, and provide actionable insights for recruiters.</p>\n",
    "                    </div>\n",
    "                </div>\n",
    "                <div class=\"feature col text-justify\">\n",
    "                    <div>\n",
    "                        <h2>ü•á Wordcloud Analysis</h2>\n",
    "                        <p>Visualize key strengths and skills with personalized word clouds, offering a quick and intuitive way to analyze each candidate's profile.</p>\n",
    "                    </div>\n",
    "                </div>\n",
    "                </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>\n",
    "<div class=\"px-4 py-5 my-5 text-left d-flex align-items-center page\">\n",
    "    <div>\n",
    "        <div class=\"col-lg-10 mx-auto\">\n",
    "            <h1 class=\"\">Tech Stack</h1>\n",
    "            <br>\n",
    "            <div class=\"row\">\n",
    "                <div class=\"feature col text-justify m-1\">\n",
    "                    <h3 class=\"font-monospace\">üõ†Ô∏è Python</h3>\n",
    "                    <p class=\"small\">Chosen for its versatility and vast libraries, making it ideal for NLP and data-driven tasks.</p>\n",
    "                </div>\n",
    "                <div class=\"feature col text-justify m-1\">\n",
    "                    <h3 class=\"font-monospace\">üß† NLP</h3>\n",
    "                    <p class=\"small\">Processes and analyzes textual data, removes stopwords, and lemmatized data to extract meaningful insights and enhance resume analysis.</p>\n",
    "                </div>\n",
    "                <div class=\"feature col text-justif m-1y\">\n",
    "                    <h3 class=\"font-monospace\">ü§ñ SKLearn</h3>\n",
    "                    <p class=\"small\">Provides robust tools for implementing TF-IDF and cosine similarity for precise ranking.</p>\n",
    "                </div>\n",
    "            </div>\n",
    "            <div class=\"row\">\n",
    "                <div class=\"col m-1\">\n",
    "                    <h3 class=\"font-monospace\">üìí Jupyter</h3>\n",
    "                    <p class=\"small\">Facilitates iterative development and easy visualization of data analysis and modeling.</p>\n",
    "                </div>\n",
    "                <div class=\"col m-1\">\n",
    "                    <h3 class=\"font-monospace\">üßë‚Äçüîß PDFPlumber</h3>\n",
    "                    <p class=\"small\">Efficiently extracts text from PDF resumes, ensuring accurate content processing.</p>\n",
    "                </div>\n",
    "                <div class=\"col m-1\">\n",
    "                    <h3 class=\"font-monospace\">üé® HTML + Bootstrap</h3>\n",
    "                    <p class=\"small\">Combines HTML's structure with Bootstrap's responsive and pre-styled components to create a modern, user-friendly interface effortlessly.</p>\n",
    "                </div>\n",
    "            </div>\n",
    "            <div class=\"row\">\n",
    "                <div class=\"col m-1\">\n",
    "                    <h3 class=\"font-monospace\">üñåÔ∏è Streamlit</h3>\n",
    "                    <p class=\"small\">Simplifies the creation of an interactive, user-friendly web interface for the application.</p>\n",
    "                </div>\n",
    "                <div class=\"col m-1\">\n",
    "                    <h3 class=\"font-monospace\">üêº Pandas & Numpy</h3>\n",
    "                    <p class=\"small\">Offers powerful tools for data manipulation, cleaning, and efficient numerical computations.</p>\n",
    "                </div>\n",
    "                <div class=\"col m-1\">\n",
    "                    <h3 class=\"font-monospace\">üìà Plotly & Wordcloud</h3>\n",
    "                    <p class=\"small\">Creates interactive charts and visual word clouds to enhance the analysis and user experience.</p>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>\n",
    "'''\n",
    "\n",
    "st.markdown(html, unsafe_allow_html=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d881bc-d9ed-4386-bc7f-888c6c790ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with st.container(key=\"container\"):\n",
    "    html='''\n",
    "    <div id=\"Page3\"></div>\n",
    "    <h2 class=\"\">Step 1: Upload Resumes</h2>\n",
    "    <span class=\"text-muted\">Upload a list of resumes to rank and provide analysis</span>\n",
    "    '''\n",
    "    st.markdown(html,unsafe_allow_html=True)\n",
    "    uploaded_files = st.file_uploader(label=\"Upload PDF file\", key=\"element1\", label_visibility=\"collapsed\", type=[\"pdf\"], accept_multiple_files=True)\n",
    "\n",
    "\n",
    "    html=f'''\n",
    "            <hr/>\n",
    "            <h2>Step 2: Add Job Description</h2>\n",
    "    '''\n",
    "\n",
    "    st.markdown(html, unsafe_allow_html=True)\n",
    "    \n",
    "\n",
    "    job_description=st.text_area (\"Enter the job description\", key=\"element2\", placeholder=\"Start typing Job Description here, including requirements and responsibilities...\")\n",
    "\n",
    "    html='''\n",
    "        </div>\n",
    "        <hr/>\n",
    "        <h1>Results</h1>\n",
    "    '''\n",
    "\n",
    "    st.markdown(html, unsafe_allow_html=True)\n",
    "    if uploaded_files and job_description:\n",
    "        \n",
    "        resume_content = []\n",
    "        resumes=[]\n",
    "        job_description=process(job_description)\n",
    "\n",
    "        # Process each resume\n",
    "        for file in uploaded_files:\n",
    "            text = extract_text_from_pdf(file)\n",
    "            resumes.append(text)\n",
    "            text=process(text)\n",
    "            \n",
    "            # Check only for words of resume that are present in the job description. This is because the resume can also contain details about various projects, such as name of the project and implemeentation information, which may not be present in the job description, leading to inaccuracies in ranking.\n",
    "            text=[word for word in text.split(' ') if word in job_description.split(' ')]\n",
    "            resume_content.append(' '.join(text))\n",
    "        \n",
    "        # Rank resumes\n",
    "        scores = rank_resumes(job_description, resume_content)\n",
    "\n",
    "        results=[]\n",
    "\n",
    "        # Make a list of format [file_name, file_content, resume_content, score]\n",
    "        # Where resume_content: processed file_content\n",
    "        \n",
    "        for i in range(len(resumes)):\n",
    "            results.append([uploaded_files[i].name, extract_text_from_pdf(uploaded_files[i]), resume_content[i], round(scores[i]*100, 2)])\n",
    "\n",
    "        # Sort results by score\n",
    "        results.sort(key=lambda x:x[3], reverse=True)\n",
    "\n",
    "        # Format and display results \n",
    "        table=\"<table>\"\n",
    "        table+=\"\"\"\n",
    "        <thead>\n",
    "            <tr>\n",
    "                <th></th>\n",
    "                <th>File Name</th>\n",
    "                <th>Score</th>\n",
    "            </tr>\n",
    "        </thead>\n",
    "        \"\"\"\n",
    "\n",
    "        table+=\"<tbody>\"\n",
    "        i=1\n",
    "        for file_name, fc, content, score in results:\n",
    "            table+=f\"<tr><td>{i}</td><td>{file_name}</td><td>{score}%</td></tr>\"\n",
    "            i+=1\n",
    "        \n",
    "        table+=\"</tbody>\"\n",
    "        table+=\"</table>\"\n",
    "\n",
    "        st.markdown(table, unsafe_allow_html=True)\n",
    "\n",
    "        # Individually Analyze each resume\n",
    "        st.subheader(\"Individual Analysis\")\n",
    "        for file_name, file_content, content, score in results:\n",
    "            html_str=f\"<h4>{file_name}</h4>\"\n",
    "            html_str+=f\"<h5>Score: {score}%</h5>\"\n",
    "\n",
    "            # Code for progress bar\n",
    "            \n",
    "            html_str += f\"\"\"\n",
    "            <div class=\"progress\" role=\"progressbar\" aria-label=\"Warning example\" aria-valuenow=\"{score}\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
    "                <div class=\"progress-bar bg-success\" style=\"width:{score}%; color: white\">{score}%</div>\n",
    "            </div>\n",
    "            <br/>\n",
    "            <p class=\"text-muted\">Add Missing Keywords given in the 'Missing Keywords' section to enhance your score</p>\n",
    "            \"\"\"\n",
    "            st.markdown(html_str, unsafe_allow_html=True)\n",
    "\n",
    "            # Highlighted Analysis\n",
    "            html='''\n",
    "            <h4>Outcome:</h4>\n",
    "            <p class=\"text-muted\">Highlighted words are keywords from job description that are included in the resume</p>\n",
    "            <div>'''\n",
    "            file_content = file_content.replace('\\n', '<br>')\n",
    "            \n",
    "            for word in file_content.split(' '):\n",
    "                w=process(word)\n",
    "                if w in job_description.split(' ') and w in content.split(' '):\n",
    "                    html+=f'<mark class=\"px-2\" style=\"background:rgba(104, 251, 170, 0.7)\">{word}</mark> '\n",
    "                else:\n",
    "                    html+=f'<span>{word}</span> '\n",
    "            html+='</div>'\n",
    "            html+='<div>'\n",
    "            \n",
    "            st.markdown(html, unsafe_allow_html=True)\n",
    "\n",
    "            # Display WordCloud\n",
    "            wordcloud = WordCloud(background_color=None, mode='RGBA', colormap='Greens', scale=2, width=750).generate(resumes[0])\n",
    "\n",
    "            st.subheader('Word Cloud Analysis')\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(8, 4), dpi=100)\n",
    "            ax.imshow(wordcloud, interpolation='bilinear')\n",
    "\n",
    "            ax.axis('off')\n",
    "\n",
    "            plt.subplots_adjust(left=0, right=1, top=1, bottom=0)\n",
    "            ax.margins(0)\n",
    "\n",
    "            buf = io.BytesIO()\n",
    "            plt.savefig(buf, format='png', bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "            buf.seek(0)\n",
    "            \n",
    "            st.image(buf)\n",
    "            html='</div>'\n",
    "\n",
    "            # Display Missing Keywords\n",
    "            st.subheader('Missing Keywords')\n",
    "            html+='<div class=\"row px-3\">'\n",
    "            for word in set(job_description.split(' ')):\n",
    "                if word not in content.split(' '):\n",
    "                    html+=f'<span class=\"col px-3 m-1\" style=\"border: 1px solid #ccc;\">{word}</span> '\n",
    "            \n",
    "            st.markdown(html, unsafe_allow_html=True)\n",
    "\n",
    "    html='''</div><hr/></div></div>\n",
    "    <div class=\"footer\">\n",
    "    <span class=\"lead\">Developed with ‚ù§Ô∏è by <a href=\"https://sanju26honey.github.io\" class=\"text-decoration-none\">Sanju</a><br/>\n",
    "    <span class=\"text-muted\">&copy 2025 Resume Ranker & Analyzer. All Rights Reserved</span>\n",
    "    </div>\n",
    "    </div>'''\n",
    "    \n",
    "    st.markdown(html, unsafe_allow_html=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
